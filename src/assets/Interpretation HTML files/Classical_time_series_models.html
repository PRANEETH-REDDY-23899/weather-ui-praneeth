
<!DOCTYPE html>
<html>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script> 

</head>
<body>

<h2>Classical time series models</h2>
<p> 
    Time series models are used to forecast events based on verified historical data. 
    Common types include ARIMA, smooth-based, and moving average. Not all models will 
    yield the same results for the same dataset, so it's critical to determine which 
    one works best based on the individual time series.
</p>

<h3>Autoregression</h3>
<p>
    Autoregression is a time series model that uses observations from previous time 
    steps as input to a regression equation to predict the value at the next time 
    step. It is a very simple idea that can result in accurate forecasts on a range 
    of time series problems. A regression model, such as linear regression, models an
     output value based on a linear combination of input values.
</p>
<p>
    An autoregression model makes an assumption that the observations at 
    previous time steps are useful to predict the value at the next time step. 
    This relationship between variables is called correlation. If both variables 
    change in the same direction (e.g. go up together or down together), this is 
    called a positive correlation. If the variables move in opposite directions as 
    values change (e.g. one goes up and one goes down), then this is called negative 
    correlation.
</p>

<p>
    We can use statistical measures to calculate the correlation between the 
    output variable and values at previous time steps at various different lags. 
    The stronger the correlation between the output variable and a specific lagged 
    variable, the more weight that autoregression model can put on that variable when 
    modeling. Again, because the correlation is calculated between the variable and 
    itself at previous time steps, it is called an autocorrelation. It is also called 
    serial correlation because of the sequenced structure of time series data. The 
    correlation statistics can also help to choose which lag variables will be useful 
    in a model and which will not.
</p>

<p>
    We could calculate the linear regression model manually using the LinearRegession 
    class in scikit-learn and manually specify the lag input variables to use. 
    Alternately, the statsmodels library provides an autoregression model where you 
    must specify an appropriate lag value and trains a linear regression model. 
    It is provided in the AutoReg class. We can use this model by first creating 
    the model AutoReg() and then calling fit() to train it on our dataset. 
    This returns an AutoRegResults object. Once fit, we can use the model to make a 
    prediction by calling the predict() function for a number of observations in 
    the future. 
    <a href="https://www.statsmodels.org/dev/generated/statsmodels.tsa.ar_model.AutoReg.html">Link to the AutoReg class</a>   
</p>

<p>
Some resources for autoregression: <br>
1. <a href="https://machinelearningmastery.com/autoregression-models-time-series-forecasting-python">Autoregression Models for Time Series Forecasting With Python</a> <br>
2. <a href="https://online.stat.psu.edu/stat501/lesson/14/14.1">Autoregressive Models</a>   <br>
</p> 

<h3> Autoregressive Integrated Moving Average (ARIMA) </h3>

<p>
    Autoregressive Integrated Moving Average (ARIMA) model uses time-series data 
    and statistical analysis to interpret the data and make future predictions. 
    The ARIMA model aims to explain data by using time series data on its past values
     and uses linear regression to make predictions.
</p> 

<p>
The following descriptive acronym explains the meaning of each of the key components of the ARIMA model:
1. The “AR” in ARIMA stands for autoregression, indicating that the model uses 
the dependent relationship between current data and its past values. 
In other words, it shows that the data is regressed on its past values. <br>
2. The “I” stands for integrated, which means that the data is stationary. 
Stationary data refers to time-series data that has been made “stationary” by 
subtracting the observations from the previous values. <br>
3. The “MA” stands for moving average model, indicating that the forecast or 
outcome of the model depends linearly on the past values. Also, it means that 
the errors in forecasting are linear functions of past errors. Note that the 
moving average models are different from statistical moving averages. <br>
</p>

<p>
    Equation 1:
    $$y_t = I + \alpha_1 y_{t-1} + \alpha_2 y_{t-2} + ... + \alpha_p y_{t-p} + 
    e_t + \theta_1 e_{t-1} + \theta_2 e_{t-2} + ... + \theta_q e_{t-q} $$ 
</p>

<p>
    Eq. (1) shows the parameter p is the number of autoregressive terms or the 
    number of “lag observations.” It is also called the “lag order,” and it 
    determines the outcome of the model by providing lagged data points. On the other 
    hand, the parameter d is known as the degree of differencing. It indicates the 
    number of times the lagged indicators have been subtracted to make the data 
    stationary. Finally, the parameter q is the number of forecast errors in the 
    model and is also referred to as the size of the moving average window. This is 
    called the ARIMA(p, d, q) model. Estimating the coefficients alpha and theta for 
    a given p, d, q is what ARIMA does when it learns from the training data in a time 
    series. ACF and PACF plots can help to get an idea for p and q values. 
<a href="https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html">Link to the ARIMA class</a> <br>
    


</p>

<p>
    Although ARIMA models can be highly accurate and reliable under the appropriate 
    conditions and data availability, one of the key limitations of the model is 
    that the parameters (p, d, q) need to be manually defined; therefore, 
    finding the most accurate fit can be a long trial-and-error process. Similarly, 
    the model depends highly on the reliability of historical data and the 
    differencing of the data. It is important to ensure that data was collected 
    accurately and over a long period of time so that the model provides accurate 
    results and forecasts. More cons include: <br>
1. Exponential time complexity: When the value of p and q increases there 
are equally more coefficients to fit hence increasing the time complexity 
manifold if p and q are high. This makes ARIMA hard to put
 into production and makes Data Scientists look into Prophet and other algorithms. 
 Then again, it depends on the complexity of the dataset too. <br>
2. Complex data: There can be a possibility where your data is too complex and 
there is no optimal solution for p and q. Although highly unlikely that ARIMA would 
fail but if this occurs then unfortunately you may have to look elsewhere. <br>
3. Amount of data needed: Both the algorithms require considerable data to work on, 
especially if the data is seasonal. For example, using three years of historical 
demand is likely not to be enough (Short Life-Cycle Products) for a good forecast. <br>

</p>

<p>
    <p>
        Some more resources on ARIMA: <br>
        1. <a href="https://www.investopedia.com/terms/a/autoregressive-integrated-moving-average-arima.asp">Investopedia - Autoregressive Integrated Moving Average (ARIMA)</a> <br>
        2. <a href="https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average">Wikipedia - Autoregressive Integrated Moving Average (ARIMA)</a>   <br>
        3. <a href="https://www.sciencedirect.com/topics/mathematics/autoregressive-integrated-moving-average">Science Direct - Autoregressive Integrated Moving Average (ARIMA)</a>   <br>
        </p> 
</p>

<h3> Seasonal Autoregressive Integrated Moving Average (SARIMA) </h3>

<p>
    Like ARIMA, SARIMA uses past values but also takes into account any seasonality 
    patterns. Since SARIMA brings in seasonality as a parameter, it is 
    significantly more powerful than ARIMA in forecasting complex data spaces 
    containing cycles. SARIMA stands for Seasonal-ARIMA and it includes seasonality 
    contribution to the forecast. The importance of seasonality is quite evident 
    and ARIMA fails to encapsulate that information implicitly.
</p>

<p>
    The Autoregressive (AR), Integrated (I), and Moving Average (MA) parts of the 
    model remain as that of ARIMA. The addition of seasonality adds robustness to the 
    SARIMA model. It is represented by the non seasonal part (p, d ,q) and  the 
    seasonal part (P, D, Q)m. Here m is the number of observations per year. 
    We use the uppercase notation for the seasonal parts of the model, and 
    lowercase notation for the non-seasonal parts of the model. Similar to ARIMA, 
    the P,D,Q values for seasonal parts of the model can be deduced from the ACF 
    and PACF plots of the data. SARIMA can be implemented with the same class as ARIMA 
    by adding values to the seasonal order. 
<a href="https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html">Link to the SARIMA class</a> <br>

</p>

<p>
    SARIMA has similar drawbacks as that of ARIMA.
</p>

<p>
Some more resources on ARIMA: <br>
1. <a href="https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/">A Gentle Introduction to SARIMA for Time Series Forecasting in Python</a>   <br>
2. <a href="https://otexts.com/fpp2/seasonal-arima.html">Seasonal ARIMA models</a>   <br>
3. <a href="https://neptune.ai/blog/arima-sarima-real-world-time-series-forecasting-guide">ARIMA & SARIMA: Real-World Time Series Forecasting</a>   <br>
4. <a href="https://medium.com/@kfoofw/seasonal-lags-sarima-model-fa671a858729">Seasonal lags: SARIMA modelling and forecasting</a>   <br>




</p>



<h2>Resources on more classical time series models</h2>
<p> 
1. <a href="https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/">11 different classical time series forecasting methods in python</a>   <br>
2. <a href="https://shaileydash.medium.com/an-overview-of-time-series-forecasting-models-part-1-classical-time-series-forecasting-models-2d877de76e0f">An Overview of Time Series Forecasting Models Part 1: Classical Time Series Forecasting Models</a>   <br>
3. <a href="https://neptune.ai/blog/select-model-for-time-series-prediction-task">How to Select a Model For Your Time Series Prediction Task</a>   <br>
4. <a href="https://www.influxdata.com/time-series-forecasting-methods">Time series forecasting methods</a>   <br>


 </p>





</body>
</html>
